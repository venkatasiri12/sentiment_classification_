{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f593791a",
   "metadata": {},
   "source": [
    "# 08_fastapi_inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57289ad",
   "metadata": {},
   "source": [
    "FastAPI inference server and Dockerfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec0e413",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastapi_code = '''from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import joblib, os\n",
    "app = FastAPI()\n",
    "class Item(BaseModel): text: str\n",
    "tf_art = 'artifacts/tfidf/lr_tfidf.joblib'\n",
    "tf_pkg = joblib.load(tf_art) if os.path.exists(tf_art) else None\n",
    "@app.post('/predict/tfidf')\n",
    "def predict(item: Item):\n",
    "    if tf_pkg is None: return {'error':'no model'}\n",
    "    model = tf_pkg['model']; vect = tf_pkg['vectorizer']\n",
    "    return {'label': int(model.predict(vect.transform([item.text]))[0])}\n",
    "'''\n",
    "with open('fastapi_app.py','w',encoding='utf-8') as f: f.write(fastapi_code)\n",
    "docker = '''FROM python:3.10-slim\n",
    "WORKDIR /app\n",
    "COPY . /app\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "CMD [\"uvicorn\",\"fastapi_app:app\",\"--host\",\"0.0.0.0\",\"--port\",\"8000\"]'''\n",
    "with open('Dockerfile','w',encoding='utf-8') as f: f.write(docker)\n",
    "print('Wrote fastapi_app.py and Dockerfile')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
